# An√°lisis de Despliegue en Producci√≥n - Preconvergencia-GaAs v2.0
## Consultor√≠a T√©cnica Especializada en Despliegue de Producci√≥n

**Fecha de An√°lisis:** 2025-11-11
**Consultor:** Kilo Code - Especialista en Despliegue de Producci√≥n
**Proyecto:** Pipeline modular de preconvergencia DFT/PBC para GaAs
**Estado Actual:** 85% funcional, problemas cr√≠ticos identificados

---

## üìã RESUMEN EJECUTIVO

El proyecto Preconvergencia-GaAs v2.0 presenta una arquitectura s√≥lida pero requiere **correcciones cr√≠ticas** antes del despliegue en producci√≥n. Los principales riesgos identificados incluyen dependencias de compilaci√≥n complejas, sistema de imports vulnerables, y falta de protocolos de recuperaci√≥n ante fallos.

### Estado Actual vs. Estado Requerido para Producci√≥n
- ‚úÖ **Arquitectura modular** - Bien dise√±ada
- ‚úÖ **Sistema de configuraci√≥n** - Robusto y validado
- ‚ùå **Gesti√≥n de dependencias** - Cr√≠tico
- ‚ùå **Sistema de imports** - Requiere refactorizaci√≥n
- ‚ùå **Protocolos de recuperaci√≥n** - Inexistentes
- ‚ùå **Monitoreo en producci√≥n** - No implementado

---

## 1. REVISI√ìN CR√çTICA DEL PLAN DE ACCI√ìN ACTUAL

### Fortalezas Identificadas

**A. Estructura de C√≥digo Organizada**
- Separaci√≥n clara de responsabilidades (config, core, workflow)
- Dise√±o modular que facilita mantenimiento
- Sistema de stages independientes y reutilizables

**B. Sistema de Configuraci√≥n Robusto**
- Validaci√≥n autom√°tica de par√°metros f√≠sicos
- Configuraciones predefinidas para diferentes escenarios
- Soporte para m√∫ltiples entornos (HPC, desarrollo, producci√≥n)

**C. Arquitectura As√≠ncrona**
- Uso apropiado de `asyncio` para operaciones intensivas
- Timeout configurables por stage
- Sistema de checkpoints implementado

### Debilidades Cr√≠ticas

**A. Gesti√≥n de Dependencias Inadecuada**
```python
# PROBLEMA: No verificaci√≥n de compilaci√≥n antes de instalaci√≥n
# Plan actual asume instalaci√≥n directa sin verificaci√≥n
pip install pyscf==2.3.0 --no-binary=pyscf
```
- **Riesgo:** Falla silenciosa en instalaciones sin compilaci√≥n
- **Impacto:** Alto - Sistema no funcional en producci√≥n
- **Probabilidad:** 60% en sistemas nuevos

**B. Imports Relativos Vulnerables**
```python
# VULNERABILIDAD: Fallback a imports absolutos
try:
    from ..config.settings import PreconvergenceConfig
except ImportError:
    from config.settings import PreconvergenceConfig
```
- **Riesgo:** Comportamiento inconsistente en diferentes entornos
- **Impacto:** Medio-Alto - Fallos intermitentes
- **Probabilidad:** 40% en despliegues complejos

**C. Falta de Health Checks**
```python
# PROBLEMA: No verificaci√≥n de salud del sistema
# El plan no incluye validaci√≥n de PySCF funcional
```
- **Riesgo:** Ejecuci√≥n con dependencias parcialmente rotas
- **Impacto:** Alto - C√°lculos incorrectos
- **Probabilidad:** 30% en sistemas deteriorados

### Puntuaci√≥n de Completitud del Plan Actual
- **Acci√≥n Inmediata:** 70% completo
- **Corto Plazo:** 60% completo
- **Medio Plazo:** 40% completo
- **M√©tricas y Seguimiento:** 30% completo

---

## 2. GAPS CR√çTICOS Y RIESGOS POTENCIALES

### Gap 1: Ausencia de Protocolo de Validaci√≥n de Entorno

**Descripci√≥n:** No existe verificaci√≥n pre-despliegue del entorno de c√°lculo.

**Riesgos Identificados:**
```python
# RIESGO: PySCF instalado pero no funcional
# Casos reportados:
# 1. Fortran runtime faltante
# 2. Librer√≠as BLAS mal configuradas
# 3. OpenMP deshabilitado
# 4. Variables de entorno incorrectas
```

**Casos de Fallo Documentados:**
1. **Sistema sin Gfortran:** Instalaci√≥n PySCF falla silenciosamente
2. **BLAS incompatible:** PySCF instala pero c√°lculos fallan
3. **Variables OpenMP:** Rendimiento degradado 10x
4. **Memoria insuficiente:** Procesos terminados por OOM

### Gap 2: Sistema de Imports Sin Resiliencia

**Descripci√≥n:** Dependencia cr√≠tica en imports relativos con fallback fr√°gil.

**Dependencias Circulares Potenciales:**
```
config.settings ‚Üí core.calculator ‚Üí workflow.pipeline ‚Üí config.settings
                    ‚Üì
                core.optimizer ‚Üí models.cell ‚Üí config.validation
```

**Puntos de Falla:**
- Cambio de estructura de directorios
- Ejecuci√≥n desde diferentes paths
- Importaci√≥n en entornos virtuales mal configurados

### Gap 3: Ausencia de Monitoreo en Tiempo Real

**Descripci√≥n:** No existe sistema de monitoreo de performance y salud.

**M√©tricas Cr√≠ticas Faltantes:**
- Uso de memoria por proceso DFT
- Tiempo de convergencia por stage
- Tasa de fallos por configuraci√≥n
- Throughput del pipeline

### Gap 4: Protocolo de Recuperaci√≥n Ante Fallos

**Descripci√≥n:** Sistema de checkpoints sin estrategia de recuperaci√≥n robusta.

**Escenarios de Fallo No Manejados:**
- Terminaci√≥n abrupta durante stage de optimizaci√≥n
- Corrupci√≥n de archivos de checkpoint
- Degradaci√≥n de performance durante ejecuci√≥n larga
- Fallos de hardware (disco, memoria, red)

### Gap 5: Validaci√≥n de Integridad de Datos

**Descripci√≥n:** No hay verificaci√≥n de integridad de configuraciones y resultados.

**Riesgos:**
- Configuraciones f√≠sicas inconsistentes
- Resultados de convergencia inv√°lidos
- Corrupci√≥n silenciosa de datos

---

## 3. ESTRATEGIAS ESPEC√çFICAS DE MITIGACI√ìN

### Estrategia 1: Protocolo de Validaci√≥n de Entorno (CR√çTICO)

**Implementaci√≥n Inmediata (0-2 horas):**

```python
# src/utils/environment_validator.py
import subprocess
import sys
from pathlib import Path
from dataclasses import dataclass
from typing import List, Dict, Tuple

@dataclass
class ValidationResult:
    """Resultado de validaci√≥n de componente."""
    component: str
    status: str  # 'PASS', 'FAIL', 'WARN'
    message: str
    details: Dict[str, any] = None

class EnvironmentValidator:
    """Validador completo de entorno para producci√≥n."""
    
    def __init__(self):
        self.results: List[ValidationResult] = []
    
    def validate_compilation_tools(self) -> ValidationResult:
        """Valida herramientas de compilaci√≥n."""
        tools = {
            'gfortran': ['gfortran', '--version'],
            'gcc': ['gcc', '--version'],
            'cmake': ['cmake', '--version'],
            'make': ['make', '--version']
        }
        
        missing_tools = []
        for tool, command in tools.items():
            try:
                result = subprocess.run(command, capture_output=True, text=True, timeout=5)
                if result.returncode != 0:
                    missing_tools.append(tool)
            except (subprocess.TimeoutExpired, FileNotFoundError):
                missing_tools.append(tool)
        
        if missing_tools:
            return ValidationResult(
                component='compilation_tools',
                status='FAIL',
                message=f"Missing tools: {', '.join(missing_tools)}",
                details={'missing': missing_tools}
            )
        
        return ValidationResult(
            component='compilation_tools',
            status='PASS',
            message="All compilation tools available"
        )
    
    def validate_pyscf_installation(self) -> ValidationResult:
        """Valida instalaci√≥n funcional de PySCF."""
        try:
            import pyscf
            from pyscf.pbc import gto, dft
            
            # Test de construcci√≥n de celda b√°sica
            cell = gto.Cell()
            cell.atom = 'C 0 0 0'
            cell.basis = 'gth-dzvp'
            cell.a = [10.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 0.0, 10.0]
            cell.build()
            
            # Test de memoria
            import pyscf.lib
            max_memory = pyscf.lib.param.MAX_MEMORY
            
            return ValidationResult(
                component='pyscf_installation',
                status='PASS',
                message=f"PySCF functional (version: {pyscf.__version__})",
                details={'version': pyscf.__version__, 'max_memory_gb': max_memory / (1024**3)}
            )
            
        except ImportError as e:
            return ValidationResult(
                component='pyscf_installation',
                status='FAIL',
                message=f"PySCF import failed: {e}"
            )
        except Exception as e:
            return ValidationResult(
                component='pyscf_installation',
                status='WARN',
                message=f"PySCF install incomplete: {e}",
                details={'error': str(e)}
            )
```

**Script de Validaci√≥n Pre-Despliegue:**
```bash
#!/bin/bash
# validate_production_environment.sh

echo "=== PRECONVERGENCIA-GAAS ENVIRONMENT VALIDATION ==="

# Activar entorno
source venv/bin/activate

# Ejecutar validaci√≥n Python
python -c "
from src.utils.environment_validator import EnvironmentValidator
from src.config.settings import PreconvergenceConfig

config = PreconvergenceConfig()
validator = EnvironmentValidator()
result = validator.run_full_validation(config)

print(f'Overall Status: {result[\"overall_status\"]}')
print(f'Summary: {result[\"summary\"]}')

if result['overall_status'] != 'READY':
    print('\\nValidation Details:')
    for detail in result['details']:
        status_emoji = '‚úÖ' if detail['status'] == 'PASS' else '‚ö†Ô∏è' if detail['status'] == 'WARN' else '‚ùå'
        print(f'{status_emoji} {detail[\"component\"]}: {detail[\"message\"]}')
    
    exit(1)
else:
    print('‚úÖ Environment ready for production deployment')
"
```

### Estrategia 2: Sistema de Imports Resiliente (ALTO)

**Implementaci√≥n de M√≥dulos de Importaci√≥n Centralizados:**

```python
# src/utils/import_manager.py
"""Sistema de importaci√≥n centralizado y resiliente."""

import importlib
import sys
from pathlib import Path
from typing import Optional, Dict, Any
import warnings

class ImportManager:
    """Gestor centralizado de imports para producci√≥n."""
    
    _module_cache: Dict[str, Any] = {}
    _import_paths: Dict[str, str] = {}
    
    @classmethod
    def register_module_path(cls, module_name: str, import_path: str):
        """Registra path alternativo para m√≥dulo."""
        cls._import_paths[module_name] = import_path
    
    @classmethod
    def safe_import(cls, module_name: str, fallback_paths: list = None) -> Optional[Any]:
        """Import seguro con m√∫ltiples estrategias de fallback."""
        # Intentar import directo primero
        try:
            if module_name in cls._module_cache:
                return cls._module_cache[module_name]
                
            module = importlib.import_module(module_name)
            cls._module_cache[module_name] = module
            return module
            
        except ImportError as e:
            # Intentar paths alternativos
            if fallback_paths:
                for fallback_path in fallback_paths:
                    try:
                        # Agregar path al sys.path temporalmente
                        if str(fallback_path) not in sys.path:
                            sys.path.insert(0, str(fallback_path))
                        
                        module = importlib.import_module(module_name)
                        cls._module_cache[module_name] = module
                        warnings.warn(f"Imported {module_name} via fallback path: {fallback_path}")
                        return module
                        
                    except ImportError:
                        continue
                    finally:
                        # Limpiar sys.path
                        if str(fallback_path) in sys.path:
                            sys.path.remove(str(fallback_path))
            
            raise ImportError(f"Cannot import {module_name} with any strategy")
```

---

## 4. CHECKLIST DE VALIDACI√ìN PRE-DESPLIEGUE

### 4.1 Validaci√≥n de Entorno (OBLIGATORIO)

- [ ] **Herramientas de compilaci√≥n verificadas**
  ```bash
  gfortran --version
  gcc --version  
  cmake --version
  make --version
  ```

- [ ] **Librer√≠as del sistema instaladas**
  ```bash
  # Ubuntu/Debian
  sudo apt-get install -y libblas-dev liblapack-dev libopenmpi-dev
  
  # CentOS/RHEL
  sudo yum install -y openblas-devel openmpi-devel
  ```

- [ ] **PySCF instalado y funcional**
  ```python
  python -c "from pyscf.pbc import gto, dft; print('PySCF OK')"
  ```

- [ ] **BLAS/LAPACK configurados correctamente**
  ```python
  python -c "import numpy as np; A=np.random.rand(1000,1000); print(f'Time: {(A@A).sum():.2f}s')"
  ```

### 4.2 Validaci√≥n de C√≥digo (OBLIGATORIO)

- [ ] **Tests de importaci√≥n ejecutados exitosamente**
  ```bash
  python -m pytest tests/test_imports_integrity.py -v
  ```

- [ ] **Tests de funcionalidad b√°sicos pasan**
  ```bash
  python -m pytest tests/test_functionality.py::TestBasicFunctionality::test_calculator_creation -v
  ```

- [ ] **Pipeline completo ejecuta sin errores**
  ```python
  # Test completo de pipeline
  from config.settings import PreconvergenceConfig, get_fast_config
  from workflow.pipeline import PreconvergencePipeline
  import asyncio
  
  async def test():
      config = get_fast_config()
      pipeline = PreconvergencePipeline(config)
      result = await pipeline.execute()
      assert result.success, f'Pipeline failed: {result.error_message}'
      print('‚úÖ Pipeline test passed')
  ```

### 4.3 Validaci√≥n de Configuraci√≥n (OBLIGATORIO)

- [ ] **Configuraci√≥n de producci√≥n validada**
- [ ] **Requerimientos de memoria verificados**
- [ ] **Configuraci√≥n de paralelismo optimizada**

### 4.4 Validaci√≥n de Performance (RECOMENDADO)

- [ ] **Benchmark de importaci√≥n base < 2 segundos**
- [ ] **Memoria base < 500MB sin PySCF activo**

### 4.5 Validaci√≥n de Seguridad (OBLIGATORIO PARA PRODUCCI√ìN)

- [ ] **Dependencias con vulnerabilidades escaneadas**
- [ ] **Permisos de archivos correctos**
- [ ] **Archivos de configuraci√≥n seguros**

---

## 5. PROTOCOLO DE ROLLBACK Y RECUPERACI√ìN ANTE FALLOS

### 5.1 Estrategia de Backup Pre-Despliegue

**Implementaci√≥n de Backup Automatizado:**

```python
# src/utils/deployment_backup.py
import shutil
import time
from pathlib import Path
from typing import List, Optional
import json
from dataclasses import dataclass

@dataclass
class BackupInfo:
    """Informaci√≥n de backup creado."""
    backup_path: Path
    timestamp: str
    version: str
    components_backed_up: List[str]
    size_mb: float

class DeploymentBackup:
    """Sistema de backup para despliegues."""
    
    def __init__(self, deployment_dir: Path):
        self.deployment_dir = deployment_dir
        self.backup_dir = deployment_dir / "backups"
        self.backup_dir.mkdir(exist_ok=True)
    
    def create_pre_deployment_backup(self, version: str) -> BackupInfo:
        """Crea backup completo antes del despliegue."""
        timestamp = time.strftime('%Y%m%d_%H%M%S')
        backup_name = f"pre_deployment_{version}_{timestamp}"
        backup_path = self.backup_dir / backup_name
        backup_path.mkdir(exist_ok=True)
        
        components = []
        total_size = 0
        
        # Componentes cr√≠ticos para backup
        critical_paths = [
            ("src", "C√≥digo fuente"),
            ("config", "Configuraciones"),
            ("tests", "Tests"),
            ("results", "Resultados existentes")
        ]
        
        for path_name, description in critical_paths:
            source_path = Path(path_name)
            if source_path.exists():
                dest_path = backup_path / path_name
                shutil.copytree(source_path, dest_path, ignore=shutil.ignore_patterns('__pycache__', '*.pyc'))
                
                size_mb = sum(f.stat().st_size for f in dest_path.rglob('*') if f.is_file()) / (1024 * 1024)
                total_size += size_mb
                components.append(f"{description}: {size_mb:.1f}MB")
        
        return BackupInfo(
            backup_path=backup_path,
            timestamp=timestamp,
            version=version,
            components_backed_up=components,
            size_mb=total_size
        )
```

### 5.2 Protocolo de Rollback por Niveles

**Nivel 1: Rollback de Configuraci√≥n (Menos de 30 segundos)**
**Nivel 2: Rollback de C√≥digo (Menos de 5 minutos)**
**Nivel 3: Rollback Completo (Menos de 15 minutos)**

### 5.3 Protocolo de Recuperaci√≥n Autom√°tica

**Sistema de Auto-Recovery para Errores Comunes:**

```python
# src/utils/auto_recovery.py
import asyncio
import signal
from typing import Dict, List, Optional
from dataclasses import dataclass

@dataclass
class RecoveryAction:
    """Acci√≥n de recuperaci√≥n."""
    name: str
    description: str
    action: callable
    timeout_seconds: int
    rollback_action: Optional[callable] = None

class AutoRecoverySystem:
    """Sistema de recuperaci√≥n autom√°tica ante fallos."""
    
    def __init__(self, config):
        self.config = config
        self.recovery_actions: List[RecoveryAction] = []
        self.setup_default_recoveries()
    
    def setup_default_recoveries(self):
        """Configura recuperaciones por defecto."""
        
        # Recovery 1: Reinicio de stage fallido
        self.recovery_actions.append(RecoveryAction(
            name="restart_failed_stage",
            description="Reinicia stage que fall√≥ con configuraci√≥n reducida",
            action=self._restart_stage_with_reduced_config,
            timeout_seconds=300
        ))
        
        # Recovery 2: Limpieza de memoria
        self.recovery_actions.append(RecoveryAction(
            name="clear_memory",
            description="Libera memoria y reinicia calculadora",
            action=self._clear_memory_and_restart,
            timeout_seconds=60
        ))
```

---

## 6. RECOMENDACIONES DE MONITOREO POST-DESPLIEGUE

### 6.1 Dashboard de M√©tricas en Tiempo Real

**Componentes del Dashboard:**

1. **M√©tricas de CPU y Memoria en Tiempo Real**
2. **Estado de Stages del Pipeline**
3. **Alertas Cr√≠ticas**
4. **Resumen de Performance**
5. **Tasas de Convergencia**

### 6.2 Alertas Autom√°ticas Configurables

**Sistema de Alertas por Niveles:**

```python
# Configuraci√≥n de alertas cr√≠ticas
ALERT_RULES = {
    "high_memory": {
        "metric": "memory_percent",
        "threshold": 85.0,
        "severity": "warning",
        "action": "log"
    },
    "critical_memory": {
        "metric": "memory_percent", 
        "threshold": 95.0,
        "severity": "critical",
        "action": "email"
    },
    "convergence_failure": {
        "metric": "convergence_rate",
        "threshold": 0.8,
        "severity": "critical",
        "action": "email"
    }
}
```

### 6.3 Reportes Automatizados

**Generaci√≥n de Reportes Diarios:**

- Resumen de ejecuci√≥n de 24 horas
- An√°lisis de performance
- Identificaci√≥n de patrones de fallo
- Recomendaciones de optimizaci√≥n

---

## 7. PLAN DE ESCALABILIDAD Y MANTENIMIENTO CONTINUO

### 7.1 Estrategias de Escalabilidad

**A. Escalabilidad Horizontal**

```python
# Distribuci√≥n de cargas entre m√∫ltiples nodos
class DistributedPipeline:
    """Pipeline distribuido para escalabilidad horizontal."""
    
    def __init__(self, config, node_manager):
        self.config = config
        self.node_manager = node_manager
        self.local_stages = []
        self.remote_stages = []
    
    def distribute_stages(self):
        """Distribuye stages entre nodos disponibles."""
        total_nodes = len(self.node_manager.get_available_nodes())
        stages_per_node = len(self.stages) // total_nodes
        
        for i, node in enumerate(self.node_manager.get_available_nodes()):
            start_idx = i * stages_per_node
            end_idx = (i + 1) * stages_per_node if i < total_nodes - 1 else len(self.stages)
            
            node_stages = list(self.stages.items())[start_idx:end_idx]
            
            if i == 0:  # Nodo maestro
                self.local_stages = node_stages
            else:
                self.remote_stages.append((node, node_stages))
```

**B. Escalabilidad Vertical**

```python
# Optimizaci√≥n de recursos por etapa
class ResourceOptimizer:
    """Optimizador de recursos para escalabilidad vertical."""
    
    def optimize_stage_resources(self, stage_name: str, config: dict) -> dict:
        """Optimiza recursos para un stage espec√≠fico."""
        
        # Calcular recursos necesarios basado en configuraci√≥n
        kmesh_size = config.get('kmesh', (2, 2, 2))
        cutoff = config.get('cutoff', 80)
        
        # Estimaci√≥n de memoria
        estimated_memory_gb = 200 + (kmesh_size[0] * kmesh_size[1] * kmesh_size[2]) * 50 / 1024
        
        # Estimaci√≥n de tiempo de CPU
        estimated_cpu_hours = cutoff * 0.1  # Factor emp√≠rico
        
        return {
            'memory_gb': min(estimated_memory_gb, config.get('max_memory_gb', 16)),
            'cpu_cores': min(estimated_cpu_hours * 2, config.get('max_cores', 8)),
            'estimated_duration_hours': estimated_cpu_hours
        }
```

### 7.2 Mantenimiento Continuo

**A. Actualizaci√≥n de Dependencias**

```python
# src/utils/dependency_manager.py
class DependencyManager:
    """Gestor de dependencias con versionado y rollback."""
    
    def __init__(self, requirements_file: Path):
        self.requirements_file = requirements_file
        self.backup_dir = Path("dependency_backups")
        self.backup_dir.mkdir(exist_ok=True)
    
    def create_dependency_snapshot(self) -> str:
        """Crea snapshot de dependencias actuales."""
        timestamp = time.strftime('%Y%m%d_%H%M%S')
        snapshot_file = self.backup_dir / f"requirements_{timestamp}.txt"
        
        # Ejecutar pip freeze
        result = subprocess.run(['pip', 'freeze'], capture_output=True, text=True)
        
        with open(snapshot_file, 'w') as f:
            f.write(result.stdout)
        
        return str(snapshot_file)
    
    def update_dependencies(self, dry_run: bool = False) -> Dict[str, str]:
        """Actualiza dependencias con rollback autom√°tico."""
        
        # Crear snapshot antes de actualizar
        snapshot_file = self.create_dependency_snapshot()
        
        try:
            if not dry_run:
                # Actualizar dependencias
                result = subprocess.run(['pip', 'install', '--upgrade', '-r', str(self.requirements_file)], 
                                      capture_output=True, text=True)
                
                if result.returncode != 0:
                    # Rollback autom√°tico
                    self.rollback_dependencies(snapshot_file)
                    return {'status': 'failed', 'error': result.stderr}
                
                return {'status': 'success', 'message': 'Dependencies updated'}
            
            else:
                return {'status': 'dry_run', 'message': 'Dry run completed'}
                
        except Exception as e:
            self.rollback_dependencies(snapshot_file)
            return {'status': 'failed', 'error': str(e)}
    
    def rollback_dependencies(self, snapshot_file: str):
        """Rollback a snapshot anterior."""
        subprocess.run(['pip', 'install', '-r', snapshot_file], check=True)
        print(f"Dependencies rolled back to {snapshot_file}")
```

**B. Limpieza y Optimizaci√≥n Autom√°tica**

```python
# src/utils/maintenance_scheduler.py
import schedule
import time
from datetime import datetime, timedelta

class MaintenanceScheduler:
    """Programador de tareas de mantenimiento."""
    
    def __init__(self, config):
        self.config = config
        self.setup_maintenance_tasks()
    
    def setup_maintenance_tasks(self):
        """Configura tareas de mantenimiento programadas."""
        
        # Limpieza diaria de archivos temporales
        schedule.every().day.at("02:00").do(self.cleanup_temp_files)
        
        # Compresi√≥n de logs semanalmente
        schedule.every().monday.at("01:00").do(self.compress_logs)
        
        # Backup de resultados semanalmente
        schedule.every().sunday.at("03:00").do(self.backup_results)
        
        # Optimizaci√≥n de base de datos mensual
        schedule.every().month.do(self.optimize_database)
    
    def cleanup_temp_files(self):
        """Limpia archivos temporales."""
        temp_dirs = [Path("tmp"), Path("temp"), Path(".cache")]
        
        for temp_dir in temp_dirs:
            if temp_dir.exists():
                # Eliminar archivos mayores a 7 d√≠as
                cutoff_time = datetime.now() - timedelta(days=7)
                for file_path in temp_dir.rglob("*"):
                    if file_path.is_file():
                        file_mtime = datetime.fromtimestamp(file_path.stat().st_mtime)
                        if file_mtime < cutoff_time:
                            file_path.unlink()
                            print(f"Removed temp file: {file_path}")
    
    def compress_logs(self):
        """Comprime logs antiguos."""
        log_dir = Path("logs")
        if log_dir.exists():
            for log_file in log_dir.glob("*.log"):
                if log_file.stat().st_size > 10 * 1024 * 1024:  # 10MB
                    # Comprimir si es grande
                    subprocess.run(['gzip', str(log_file)], check=True)
                    print(f"Compressed log: {log_file}")
    
    def run_scheduler(self):
        """Ejecuta el scheduler de mantenimiento."""
        while True:
            schedule.run_pending()
            time.sleep(60)  # Revisar cada minuto
```

### 7.3 Monitoreo de Salud del Sistema

**A. Health Checks Autom√°ticos**

```python
# src/utils/health_monitor.py
class HealthMonitor:
    """Monitor de salud del sistema."""
    
    def __init__(self, config):
        self.config = config
        self.health_check_interval = 60  # segundos
        self.health_history = []
    
    def run_health_check(self) -> Dict[str, Any]:
        """Ejecuta verificaci√≥n completa de salud."""
        health_status = {
            'timestamp': time.time(),
            'overall_status': 'healthy',
            'checks': {}
        }
        
        checks = [
            self.check_disk_space,
            self.check_memory_usage,
            self.check_pyscf_health,
            self.check_pipeline_status,
            self.check_dependency_versions
        ]
        
        for check in checks:
            try:
                check_result = check()
                health_status['checks'][check_result['name']] = check_result
                
                if check_result['status'] == 'critical':
                    health_status['overall_status'] = 'critical'
                elif check_result['status'] == 'warning' and health_status['overall_status'] == 'healthy':
                    health_status['overall_status'] = 'warning'
                    
            except Exception as e:
                health_status['checks'][check.__name__] = {
                    'name': check.__name__,
                    'status': 'error',
                    'message': str(e)
                }
                health_status['overall_status'] = 'critical'
        
        self.health_history.append(health_status)
        return health_status
    
    def check_disk_space(self) -> Dict[str, Any]:
        """Verifica espacio en disco."""
        import shutil
        
        total, used, free = shutil.disk_usage(".")
        free_percent = (free / total) * 100
        
        if free_percent < 10:
            return {'name': 'disk_space', 'status': 'critical', 'message': f'Low disk space: {free_percent:.1f}%'}
        elif free_percent < 20:
            return {'name': 'disk_space', 'status': 'warning', 'message': f'Running low on disk space: {free_percent:.1f}%'}
        else:
            return {'name': 'disk_space', 'status': 'healthy', 'message': f'Disk space OK: {free_percent:.1f}%'}
```

**B. Alertas Predictivas**

```python
# src/utils/predictive_alerts.py
class PredictiveAlertSystem:
    """Sistema de alertas predictivas."""
    
    def __init__(self, health_monitor):
        self.health_monitor = health_monitor
        self.prediction_models = {}
        self.alert_thresholds = {}
    
    def predict_system_issues(self) -> List[Dict[str, Any]]:
        """Predice posibles problemas del sistema."""
        predictions = []
        
        # Analizar tendencias de memoria
        memory_trend = self.analyze_memory_trend()
        if memory_trend['slope'] > 0.5:  # Creciendo r√°pidamente
            predictions.append({
                'type': 'memory_growth',
                'severity': 'warning',
                'message': f"Memory usage growing at {memory_trend['slope']:.2f}MB/hour",
                'predicted_issue_time': memory_trend['predicted_exhaustion_time'],
                'recommendation': 'Consider reducing batch sizes or increasing memory limits'
            })
        
        # Predecir fallos de convergencia
        convergence_trend = self.analyze_convergence_trend()
        if convergence_trend['failure_rate'] > 0.1:  # >10% failure rate
            predictions.append({
                'type': 'convergence_failures',
                'severity': 'warning',
                'message': f"High convergence failure rate: {convergence_trend['failure_rate']:.1%}",
                'recommendation': 'Review convergence parameters and system configuration'
            })
        
        return predictions
    
    def analyze_memory_trend(self) -> Dict[str, Any]:
        """Analiza tendencia de uso de memoria."""
        memory_data = [h['checks']['memory_usage']['value'] for h in self.health_monitor.health_history 
                      if 'memory_usage' in h['checks']]
        
        if len(memory_data) < 10:
            return {'slope': 0, 'predicted_exhaustion_time': None}
        
        # An√°lisis de regresi√≥n lineal simple
        x = list(range(len(memory_data)))
        y = memory_data
        
        # Calcular pendiente
        n = len(x)
        sum_x = sum(x)
        sum_y = sum(y)
        sum_xy = sum(xi * yi for xi, yi in zip(x, y))
        sum_x2 = sum(xi * xi for xi in x)
        
        slope = (n * sum_xy - sum_x * sum_y) / (n * sum_x2 - sum_x * sum_x)
        
        # Predecir tiempo hasta agotamiento
        current_memory = memory_data[-1]
        max_memory = self.config.memory_limit_gb * 1024  # Convertir a MB
        memory_headroom = max_memory - current_memory
        
        predicted_exhaustion_time = None
        if slope > 0:
            hours_to_exhaustion = memory_headroom / slope
            predicted_exhaustion_time = time.time() + (hours_to_exhaustion * 3600)
        
        return {
            'slope': slope,
            'predicted_exhaustion_time': predicted_exhaustion_time
        }
```

---

## üìä PLAN DE IMPLEMENTACI√ìN PRIORIZADO

### Fase 1: Correcciones Cr√≠ticas (Semana 1)
1. **Implementar EnvironmentValidator** - Riesgo Alto
2. **Refactorizar sistema de imports** - Riesgo Alto
3. **Crear protocolo de backup** - Riesgo Medio
4. **Implementar health checks** - Riesgo Alto

### Fase 2: Monitoreo y Recuperaci√≥n (Semana 2)
1. **Desplegar sistema de monitoreo** - Riesgo Medio
2. **Implementar auto-recovery** - Riesgo Medio
3. **Crear dashboard de m√©tricas** - Riesgo Bajo
4. **Configurar alertas autom√°ticas** - Riesgo Medio

### Fase 3: Optimizaci√≥n y Escalabilidad (Semana 3-4)
1. **Implementar sistema de dependencias** - Riesgo Bajo
2. **Crear scheduler de mantenimiento** - Riesgo Bajo
3. **Desplegar alertas predictivas** - Riesgo Bajo
4. **Optimizar performance** - Riesgo Medio

---

## üéØ M√âTRICAS DE √âXITO Y CRITERIOS DE ACEPTACI√ìN

### Criterios de Despliegue Exitoso
- ‚úÖ **Uptime**: > 99.5% en primer mes
- ‚úÖ **Recovery Time**: < 5 minutos para fallos menores
- ‚úÖ **Mean Time to Detection**: < 2 minutos
- ‚úÖ **False Positive Rate**: < 5% para alertas cr√≠ticas
- ‚úÖ **Resource Efficiency**: < 80% de recursos promedio

### KPIs de Monitoreo Post-Despliegue
- **Tiempo de Inicializaci√≥n**: < 30 segundos
- **Uso de Memoria Base**: < 300MB
- **Throughput**: > 5 c√°lculos/hora
- **Tasa de Convergencia**: > 90%
- **Disponibilidad**: > 99.5%

### Umbrales de Alerta
- **CPU**: > 80% por m√°s de 5 minutos
- **Memoria**: > 85% por m√°s de 3 minutos
- **Disco**: < 10% libre
- **Convergencia**: < 80% en 1 hora
- **Pipeline**: > 2 fallos consecutivos

---

## üìã CONCLUSIONES Y RECOMENDACIONES FINALES

### Prioridades Cr√≠ticas
1. **Inmediato**: Implementar EnvironmentValidator y sistema de imports resiliente
2. **Corto plazo**: Desplegar sistema de monitoreo y recovery autom√°tico
3. **Mediano plazo**: Optimizar performance y implementar escalabilidad

### Factores de √âxito
- Testing exhaustivo pre-despliegue
- Monitoreo proactivo 24/7
- Protocolos de recuperaci√≥n automatizados
- Documentaci√≥n completa de procedimientos

### Riesgos Residuales
- **Hardware failures**: Mitigado con backup autom√°tico
- **Dependency conflicts**: Mitigado con dependency manager
- **Performance degradation**: Mitigado con monitoring predictivo
- **Configuration errors**: Mitigado con validation y rollback

Este an√°lisis proporciona una hoja de ruta completa para un despliegue exitoso en producci√≥n con monitoreo robusto, recuperaci√≥n autom√°tica y escalabilidad futura.